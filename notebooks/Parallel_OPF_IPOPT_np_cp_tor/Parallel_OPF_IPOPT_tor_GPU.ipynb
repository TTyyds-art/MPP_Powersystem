{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-10T08:33:51.964161900Z",
     "start_time": "2023-06-10T08:33:51.004441300Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys, os\n",
    "path_current = '/home/huzuntao/PycharmProjects/MPP_Powersystem/'\n",
    "path_ = os.getcwd()\n",
    "if path_current not in sys.path:\n",
    "    sys.path.insert(1, '/home/huzuntao/PycharmProjects/MPP_Powersystem/')\n",
    "elif path_ not in sys.path:\n",
    "    sys.path.insert(1, path_)\n",
    "\n",
    "import pandapower as pp\n",
    "net = pp.create_empty_network()\n",
    "\n",
    "# create buses\n",
    "bus1 = pp.create_bus(net, vn_kv=110.)\n",
    "bus2 = pp.create_bus(net, vn_kv=110.)\n",
    "bus3 = pp.create_bus(net, vn_kv=110.)\n",
    "bus4 = pp.create_bus(net, vn_kv=110.)\n",
    "bus5 = pp.create_bus(net, vn_kv=110.)\n",
    "bus6 = pp.create_bus(net, vn_kv=110.)\n",
    "\n",
    "# create 110 kV lines\n",
    "pp.create_line(net, bus4, bus5, length_km=90., std_type='149-AL1/24-ST1A 110.0')\n",
    "pp.create_line(net, bus3, bus4, length_km=90., std_type='149-AL1/24-ST1A 110.0')\n",
    "pp.create_line(net, bus2, bus3, length_km=90., std_type='149-AL1/24-ST1A 110.0')\n",
    "pp.create_line(net, bus1, bus2, length_km=70., std_type='149-AL1/24-ST1A 110.0')\n",
    "pp.create_line(net, bus6, bus3, length_km=70., std_type='149-AL1/24-ST1A 110.0')\n",
    "\n",
    "# create loads\n",
    "p_load_1 = 10\n",
    "p_load_2 = 30\n",
    "pp.create_load(net, bus2, p_mw=p_load_1, controllable=False)\n",
    "pp.create_load(net, bus4, p_mw=p_load_2/2, controllable=False)\n",
    "pp.create_load(net, bus5, p_mw=p_load_2/2, controllable=False)\n",
    "pp.create_load(net, bus6, p_mw=p_load_2/2, controllable=False)\n",
    "# create generators\n",
    "eg = pp.create_ext_grid(net, bus1, min_p_mw=0, max_p_mw=1000, vm_pu=1.05)\n",
    "g0 = pp.create_gen(net, bus3, p_mw=80, min_p_mw=0, max_p_mw=80, vm_pu=1.00, controllable=True)\n",
    "\n",
    "costeg = pp.create_poly_cost(net, 0, 'ext_grid', cp1_eur_per_mw=20)\n",
    "costgen1 = pp.create_poly_cost(net, 0, 'gen', cp1_eur_per_mw=10)\n",
    "costgen2 = pp.create_poly_cost(net, 1, 'gen', cp1_eur_per_mw=10)\n",
    "\n",
    "net.bus[\"min_vm_pu\"] = 0.96\n",
    "net.bus[\"max_vm_pu\"] = 1.04\n",
    "net.line[\"max_loading_percent\"] = 100\n",
    "om, ppopt, raw = pp.runopp(net, delta=1e-16, RETURN_RAW_DER=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## pipscopf.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import numpy, torch\n",
    "from torch import ones, zeros, pi, exp, conj, cat, tensor\n",
    "Inf = tensor(float('inf'))\n",
    "from pypower_pych_gpu.torch_utils import find\n",
    "from pypower_pych_gpu.csr_real_imag import csr_imag\n",
    "from pypower_pych_gpu.idx_brch import F_BUS, T_BUS, RATE_A, PF, QF, PT, QT, MU_SF, MU_ST\n",
    "from pypower_pych_gpu.idx_bus import BUS_TYPE, REF, VM, VA, MU_VMAX, MU_VMIN, LAM_P, LAM_Q\n",
    "from pypower_pych_gpu.idx_cost import MODEL, PW_LINEAR, NCOST\n",
    "from pypower_pych_gpu.idx_gen import GEN_BUS, PG, QG, VG, MU_PMAX, MU_PMIN, MU_QMAX, MU_QMIN\n",
    "from pypower_pych_gpu.makeYbus import makeYbus\n",
    "from pypower_pych_gpu.opf_consfcn import opf_consfcn\n",
    "from pypower_pych_gpu.opf_costfcn import opf_costfcn\n",
    "\n",
    "# from pandapower.pypower.util import sub2ind\n",
    "\n",
    "from pypower_pych_gpu.opf_hessfcn import opf_hessfcn\n",
    "from pypower_pych_gpu.pips import pips\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pip.py\n",
    "import torch\n",
    "# from numpy import array, Inf, any, isnan, ones, r_, finfo, \\\n",
    "#     zeros, dot, absolute, log, flatnonzero as find\n",
    "# from numpy.linalg import norm\n",
    "\n",
    "# from scipy.sparse import vstack, hstack, eye, csr_matrix as sparse\n",
    "# from scipy.sparse.linalg import spsolve\n",
    "from torch import tensor, any, isnan, ones, cat, finfo, \\\n",
    "    zeros, dot, absolute, log, arange\n",
    "from pypower_pych_gpu.torch_utils import find\n",
    "from torch import asarray\n",
    "from torch.linalg import norm\n",
    "Inf = tensor(float('inf'))\n",
    "\n",
    "from pypower_pych_gpu.torch_utils import vstack, hstack\n",
    "from torch import eye\n",
    "from pypower_pych_gpu.torch_utils import sparse, issparse\n",
    "# from cupyx.scipy.sparse.linalg import spsolve\n",
    "from torch.linalg import solve\n",
    "\n",
    "from pandapower.pypower.pipsver import pipsver\n",
    "\n",
    "EPS = finfo(float).eps\n",
    "    # Define the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T08:39:15.118383400Z",
     "start_time": "2023-06-05T08:39:13.805762700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: [], Cw: [], H: [], dd: [], rh: [], kk: [], mm: []\n",
      "cp: {'N': array([], shape=(0, 16), dtype=float64), 'Cw': array([], dtype=float64), 'H': array([], shape=(0, 0), dtype=float64), 'dd': array([], dtype=float64), 'rh': array([], dtype=float64), 'kk': array([], dtype=float64), 'mm': array([], dtype=float64)}\n"
     ]
    }
   ],
   "source": [
    "x0_init=None\n",
    "out_opt=None\n",
    "\n",
    "##----- initialization -----\n",
    "## optional output\n",
    "if out_opt is None:\n",
    "    out_opt = {}\n",
    "\n",
    "## options\n",
    "verbose = ppopt['VERBOSE']\n",
    "feastol = ppopt['PDIPM_FEASTOL']\n",
    "gradtol = ppopt['PDIPM_GRADTOL']\n",
    "comptol = ppopt['PDIPM_COMPTOL']\n",
    "costtol = ppopt['PDIPM_COSTTOL']\n",
    "max_it  = ppopt['PDIPM_MAX_IT']\n",
    "max_red = ppopt['SCPDIPM_RED_IT']\n",
    "init = ppopt['INIT']\n",
    "step_control = (ppopt['OPF_ALG'] == 565)  ## OPF_ALG == 565, PIPS-sc\n",
    "if feastol == 0:\n",
    "    feastol = ppopt['OPF_VIOLATION']\n",
    "opt = {  'feastol': feastol,\n",
    "         'gradtol': gradtol,\n",
    "         'comptol': comptol,\n",
    "         'costtol': costtol,\n",
    "         'max_it': max_it,\n",
    "         'max_red': max_red,\n",
    "         'step_control': step_control,\n",
    "         'cost_mult': 1,\n",
    "         'verbose': verbose  }\n",
    "\n",
    "## unpack data TODO: move the data to GPU\n",
    "ppc = om.get_ppc()\n",
    "baseMVA, bus, gen, branch, gencost = tensor(ppc[\"baseMVA\"], device=device), tensor(ppc[\"bus\"], device=device), tensor(ppc[\"gen\"], device=device), \\\n",
    " tensor(ppc[\"branch\"], device=device), tensor(ppc[\"gencost\"], device=device)\n",
    "vv, _, nn, _ = om.get_idx()\n",
    "# vv, nn = tensor(vv), tensor(nn)\n",
    "## problem dimensions\n",
    "nb = bus.shape[0]          ## int: number of buses\n",
    "nl = branch.shape[0]       ## int: number of branches\n",
    "ny = om.getN('var', 'y')   ## int: number of piece-wise linear costs\n",
    "\n",
    "## linear constraints\n",
    "A, l, u = om.linear_constraints()\n",
    "if isinstance(A, numpy.ndarray):\n",
    "    A = tensor(A, device=device)\n",
    "if isinstance(l, numpy.ndarray):\n",
    "    l = tensor(l, device=device)\n",
    "if isinstance(u, numpy.ndarray):\n",
    "    u = tensor(u, device=device)\n",
    "\n",
    "\n",
    "## bounds on optimization vars\n",
    "x0, xmin, xmax = om.getv()\n",
    "x0, xmin, xmax = tensor(x0, device=device), tensor(xmin, device=device), tensor(xmax, device=device)\n",
    "\n",
    "## build admittance matrices\n",
    "Ybus, Yf, Yt = makeYbus(baseMVA, bus, branch)\n",
    "if ('torch' not in str(type(Ybus))) or ('torch' not in str(type(Yf))) or ('torch' not in str(type(Yt))):\n",
    "    raise ValueError('Ybus/Yf/Yt must be a torch tensor')\n",
    "else:\n",
    "    Ybus = Ybus.to(device)\n",
    "    Yf = Yf.to(device)\n",
    "    Yt = Yt.to(device)\n",
    "\n",
    "## try to select an interior initial point if init is not available from a previous powerflow\n",
    "if init != \"pf\":\n",
    "    ll, uu = xmin.clone(), xmax.clone()\n",
    "    ll[xmin == -Inf] = -1e10   ## replace Inf with numerical proxies\n",
    "    uu[xmax ==  Inf] =  1e10\n",
    "    x0 = (ll + uu) / 2\n",
    "    Varefs = bus[bus[:, BUS_TYPE] == REF, VA] * (pi / 180)\n",
    "    ## angles set to first reference angle\n",
    "    x0[vv[\"i1\"][\"Va\"]:vv[\"iN\"][\"Va\"]] = Varefs[0]\n",
    "    if ny > 0:\n",
    "        pass\n",
    "\n",
    "if x0_init is not None:\n",
    "    x0 = x0_init\n",
    "\n",
    "## find branches with flow limits\n",
    "il = find((branch[:, RATE_A] != 0) & (branch[:, RATE_A].real < 1e10))\n",
    "Yf_on, Yt_on = (Yf.to_dense()[il, :]).to_sparse(layout=torch.sparse_csr), (Yt.to_dense()[il, :]).to_sparse(layout=torch.sparse_csr)\n",
    "\n",
    "nl2 = len(il)           ## number of constrained lines\n",
    "\n",
    "\n",
    "cp = om.get_cost_params()\n",
    "N, Cw, H, dd, rh, kk, mm = \\\n",
    "    cp[\"N\"], cp[\"Cw\"], cp[\"H\"], cp[\"dd\"], cp[\"rh\"], cp[\"kk\"], cp[\"mm\"]\n",
    "print(f\"N: {N}, Cw: {Cw}, H: {H}, dd: {dd}, rh: {rh}, kk: {kk}, mm: {mm}\")\n",
    "print(f\"cp: {cp}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T08:39:17.462188900Z",
     "start_time": "2023-06-05T08:39:15.822360500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "cp = [tensor(item).to(device) for item in (N, Cw, H, dd, rh, kk, mm)]\n",
    "pack_para = (0, baseMVA, bus, gen, branch, gencost, il, vv, nn, ny, cp)\n",
    "if issparse(N) and N.nnz > 0:\n",
    "    print('N is sparse')\n",
    "##-----  run opf  -----\n",
    "f_fcn = lambda x, return_hessian=False: opf_costfcn(x, pack_para, return_hessian)\n",
    "gh_fcn = lambda x: opf_consfcn(x, pack_para, Ybus, Yf_on, Yt_on, ppopt, il)\n",
    "hess_fcn = lambda x, lmbda, cost_mult: opf_hessfcn(x, lmbda, pack_para, Ybus, Yf_on, Yt_on, ppopt, il, cost_mult)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T08:39:18.337933900Z",
     "start_time": "2023-06-05T08:39:18.291829300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## pip.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: None; eyex shape: torch.Size([16, 16]); nx : 16\n",
      "Python Interior Point Solver - PIPS, Version 1.0, 07-Feb-2011\n"
     ]
    }
   ],
   "source": [
    "if isinstance(f_fcn, dict):  ## problem dict\n",
    "    p = f_fcn\n",
    "    f_fcn = p['f_fcn']\n",
    "    x0 = p['x0']\n",
    "    if 'opt' in p: opt = p['opt']\n",
    "    if 'hess_fcn' in p: hess_fcn = p['hess_fcn']\n",
    "    if 'gh_fcn' in p: gh_fcn = p['gh_fcn']\n",
    "    if 'xmax' in p: xmax = p['xmax']\n",
    "    if 'xmin' in p: xmin = p['xmin']\n",
    "    if 'u' in p: u = p['u']\n",
    "    if 'l' in p: l = p['l']\n",
    "    if 'A' in p: A = p['A']\n",
    "# print(f\"isinstance(f_fcn, dict): {isinstance(f_fcn, dict)}; x0 shape: {x0.shape}\")\n",
    "\n",
    "nx = x0.shape[0]                       # int: number of variables\n",
    "nA = A.shape[0] if A is not None else 0 # int: number of original linear constr\n",
    "\n",
    "# default argument values\n",
    "if l is None or len(l) == 0: l = -Inf * ones(nA, device=device)\n",
    "if u is None or len(u) == 0: u =  Inf * ones(nA, device=device)\n",
    "if xmin is None or len(xmin) == 0: xmin = -Inf * ones(x0.shape[0], dtype=x0.dtype).to(device)\n",
    "if xmax is None or len(xmax) == 0: xmax =  Inf * ones(x0.shape[0], dtype=x0.dtype).to(device)\n",
    "if gh_fcn is None:\n",
    "    nonlinear = False\n",
    "    gn = tensor([], device=device)\n",
    "    hn = tensor([], device=device)\n",
    "else:\n",
    "    nonlinear = True\n",
    "\n",
    "if opt is None: opt = {}\n",
    "# options\n",
    "if \"feastol\" not in opt:\n",
    "    opt[\"feastol\"] = 1e-06\n",
    "if \"gradtol\" not in opt:\n",
    "    opt[\"gradtol\"] = 1e-06\n",
    "if \"comptol\" not in opt:\n",
    "    opt[\"comptol\"] = 1e-06\n",
    "if \"costtol\" not in opt:\n",
    "    opt[\"costtol\"] = 1e-06\n",
    "if \"max_it\" not in opt:\n",
    "    opt[\"max_it\"] = 150\n",
    "if \"max_red\" not in opt:\n",
    "    opt[\"max_red\"] = 20\n",
    "if \"step_control\" not in opt:\n",
    "    opt[\"step_control\"] = False\n",
    "if \"cost_mult\" not in opt:\n",
    "    opt[\"cost_mult\"] = 1\n",
    "if \"verbose\" not in opt:\n",
    "    opt[\"verbose\"] = 0\n",
    "opt[\"verbose\"] = 1\n",
    "# initialize history\n",
    "hist = []\n",
    "\n",
    "# constants\n",
    "xi = 0.99995\n",
    "sigma = 0.1\n",
    "z0 = 1\n",
    "alpha_min = 1e-8\n",
    "rho_min = 0.95\n",
    "rho_max = 1.05\n",
    "mu_threshold = 1e-5\n",
    "\n",
    "# initialize\n",
    "i = 0                       # iteration counter\n",
    "converged = False           # flag\n",
    "eflag = False               # exit flag\n",
    "\n",
    "# add var limits to linear constraints\n",
    "eyex = eye(nx, nx, dtype=torch.float64, device=device)\n",
    "print(f\"A: {A}; eyex shape: {eyex.shape}; nx : {nx}\")\n",
    "AA = eyex if A is None else vstack([eyex, A], \"csr\")\n",
    "ll = cat([xmin, l])\n",
    "uu = cat([xmax, u])\n",
    "\n",
    "# split up linear constraints\n",
    "ieq = find( absolute(uu - ll) <= EPS )\n",
    "igt = find( (uu >=  1e10) & (ll > -1e10) )\n",
    "ilt = find( (ll <= -1e10) & (uu <  1e10) )\n",
    "ibx = find( (absolute(uu - ll) > EPS) & (uu < 1e10) & (ll > -1e10) )\n",
    "# zero-sized sparse matrices unsupported\n",
    "# print(f'ieq_: {ieq};AA shape: {AA.shape}')\n",
    "Ae = AA[ieq, :] if len(ieq) else None\n",
    "if len(ilt) or len(igt) or len(ibx):\n",
    "    idxs = [(1, ilt), (-1, igt), (1, ibx), (-1, ibx)]\n",
    "    Ai = vstack([sig * AA[idx, :] for sig, idx in idxs if len(idx)], 'csr')\n",
    "else:\n",
    "    Ai = None\n",
    "be = uu[ieq]\n",
    "bi = cat([uu[ilt], -ll[igt], uu[ibx], -ll[ibx]])\n",
    "x = x0\n",
    "f, df = f_fcn(x)                 # cost\n",
    "f = f * opt[\"cost_mult\"]\n",
    "df = df * opt[\"cost_mult\"]\n",
    "if nonlinear:\n",
    "    hn, gn, dhn, dgn = gh_fcn(x)        # nonlinear constraints\n",
    "    h = hn if Ai is None else cat([hn, Ai.to(torch.float64).matmul(x) - bi])  # inequality constraints\n",
    "    g = gn if Ae is None else cat([gn, Ae.to(torch.float64).matmul(x) - be])\n",
    "    if (dhn is None) and (Ai is None):\n",
    "        dh = None\n",
    "    elif dhn is None:\n",
    "        dh = Ai.T\n",
    "    elif Ai is None:\n",
    "        dh = dhn\n",
    "    else:\n",
    "        dh = hstack([dhn, Ai.T])\n",
    "\n",
    "    if (dgn is None) and (Ae is None):\n",
    "        dg = None\n",
    "    elif dgn is None:\n",
    "        dg = Ae.T\n",
    "    elif Ae is None:\n",
    "        dg = dgn\n",
    "    else:\n",
    "        dg = hstack([dgn, Ae.T])\n",
    "else:\n",
    "    h = -bi if Ai is None else Ai * x - bi        # inequality constraints\n",
    "    g = -be if Ae is None else Ae * x - be        # equality constraints\n",
    "    dh = None if Ai is None else Ai.T     # 1st derivative of inequalities\n",
    "    dg = None if Ae is None else Ae.T     # 1st derivative of equalities\n",
    "\n",
    "# some dimensions\n",
    "neq = g.shape[0]           # int: number of equality constraints\n",
    "niq = h.shape[0]           # int: number of inequality constraints\n",
    "neqnln = gn.shape[0]       # int: number of nonlinear equality constraints\n",
    "niqnln = hn.shape[0]       # int: number of nonlinear inequality constraints\n",
    "nlt = len(ilt)             # int: number of upper bounded linear inequalities\n",
    "ngt = len(igt)             # int: number of lower bounded linear inequalities\n",
    "nbx = len(ibx)             # int: number of doubly bounded linear inequalities\n",
    "\n",
    "# initialize gamma, lam, mu, z, e\n",
    "gamma = 1                  # barrier coefficient\n",
    "lam = zeros(neq, dtype=torch.float64, device=device)\n",
    "z = z0 * ones(niq, dtype=torch.float64, device=device)\n",
    "mu = z0 * ones(niq, dtype=torch.float64, device=device)\n",
    "k = find(h < -z0)\n",
    "z[k] = -h[k].double()\n",
    "k = find((gamma / z) > z0)\n",
    "mu[k] = gamma / z[k]\n",
    "e = ones(niq, dtype=torch.float64, device=device)\n",
    "\n",
    "# check tolerance\n",
    "f0 = f\n",
    "if opt[\"step_control\"]:\n",
    "    L = f + dot(lam, g) + dot(mu, h + z) - gamma * sum(log(z))\n",
    "\n",
    "Lx = df.clone()\n",
    "Lx = Lx + dg.matmul(lam) if dg is not None else Lx\n",
    "Lx = Lx + dh.matmul(mu)  if dh is not None else Lx\n",
    "\n",
    "maxh = zeros(1, device=device) if len(h) == 0 else max(h)\n",
    "\n",
    "gnorm = norm(g, Inf) if len(g) else 0.0\n",
    "lam_norm = norm(lam, Inf) if len(lam) else 0.0\n",
    "mu_norm = norm(mu, Inf) if len(mu) else 0.0\n",
    "znorm = norm(z, Inf) if len(z) else 0.0\n",
    "feascond = \\\n",
    "    max([gnorm, maxh]) / (1 + max([norm(x, Inf), znorm]))\n",
    "gradcond = \\\n",
    "    norm(Lx, Inf) / (1 + max([lam_norm, mu_norm]))\n",
    "compcond = dot(z, mu) / (1 + norm(x, Inf))\n",
    "costcond = absolute(f - f0) / (1 + absolute(f0))\n",
    "\n",
    "# save history\n",
    "hist.append({'feascond': feascond, 'gradcond': gradcond,\n",
    "    'compcond': compcond, 'costcond': costcond, 'gamma': gamma,\n",
    "    'stepsize': 0, 'obj': f / opt[\"cost_mult\"], 'alphap': 0, 'alphad': 0})\n",
    "\n",
    "if opt[\"verbose\"]: # pragma: no cover\n",
    "    s = '-sc' if opt[\"step_control\"] else ''\n",
    "    v = pipsver('all')\n",
    "    print('Python Interior Point Solver - PIPS%s, Version %s, %s' %\n",
    "                (s, v['Version'], v['Date']))\n",
    "    if opt['verbose'] > 1:\n",
    "        print(\" it    objective   step size   feascond     gradcond     \"\n",
    "              \"compcond     costcond  \")\n",
    "        print(\"----  ------------ --------- ------------ ------------ \"\n",
    "              \"------------ ------------\")\n",
    "        print(\"%3d  %12.8g %10s %12g %12g %12g %12g\" %\n",
    "            (i, (f / opt[\"cost_mult\"]), \"\",\n",
    "             feascond, gradcond, compcond, costcond))\n",
    "\n",
    "if feascond < opt[\"feastol\"] and gradcond < opt[\"gradtol\"] and \\\n",
    "    compcond < opt[\"comptol\"] and costcond < opt[\"costtol\"]:\n",
    "    converged = True\n",
    "    if opt[\"verbose\"]:\n",
    "        print(\"Converged!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T08:39:24.682269900Z",
     "start_time": "2023-06-05T08:39:19.580531900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dh.to_sparse_coo()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\t398.4826354980469\n",
      "(0, 8)\t-398.4826354980469\n",
      "(1, 2)\t379.50726318359375\n",
      "(1, 3)\t-398.4826354980469\n",
      "(1, 7)\t-379.50726318359375\n",
      "(1, 8)\t398.4826354980469\n",
      "(2, 1)\t379.50726318359375\n",
      "(2, 2)\t-379.50726318359375\n",
      "(2, 4)\t-379.50726318359375\n",
      "(2, 6)\t-379.50726318359375\n",
      "(2, 7)\t379.50726318359375\n",
      "(2, 9)\t379.50726318359375\n",
      "(3, 0)\t379.50726318359375\n",
      "(3, 1)\t-379.50726318359375\n",
      "(3, 5)\t-379.50726318359375\n",
      "(3, 6)\t379.50726318359375\n",
      "(4, 0)\t-379.50726318359375\n",
      "(4, 5)\t379.50726318359375\n",
      "(5, 4)\t379.50726318359375\n",
      "(5, 9)\t-379.50726318359375\n",
      "(6, 3)\t13643.8583984375\n",
      "(6, 8)\t15325.3203125\n",
      "(7, 2)\t-797.57080078125\n",
      "(7, 3)\t-13681.1142578125\n",
      "(7, 7)\t802.0514526367188\n",
      "(7, 8)\t-15282.5068359375\n",
      "(7, 10)\t1.0\n",
      "(7, 19)\t-1.0\n",
      "(8, 1)\t-797.57080078125\n",
      "(8, 2)\t802.0514526367188\n",
      "(8, 4)\t802.0514526367188\n",
      "(8, 6)\t802.0514526367188\n",
      "(8, 7)\t-797.57080078125\n",
      "(8, 9)\t-799.3409423828125\n",
      "(8, 11)\t1.0\n",
      "(8, 20)\t-1.0\n",
      "(9, 0)\t-797.57080078125\n",
      "(9, 1)\t802.0514526367188\n",
      "(9, 5)\t802.0514526367188\n",
      "(9, 6)\t-797.57080078125\n",
      "(9, 12)\t1.0\n",
      "(9, 21)\t-1.0\n",
      "(10, 0)\t802.0514526367188\n",
      "(10, 5)\t-797.57080078125\n",
      "(10, 13)\t1.0\n",
      "(10, 22)\t-1.0\n",
      "(11, 4)\t-799.3409423828125\n",
      "(11, 9)\t802.0514526367188\n",
      "(11, 14)\t1.0\n",
      "(11, 23)\t-1.0\n",
      "(12, 15)\t1.0\n",
      "(12, 24)\t-1.0\n",
      "(13, 16)\t1.0\n",
      "(13, 25)\t-1.0\n",
      "(14, 17)\t1.0\n",
      "(14, 26)\t-1.0\n",
      "(15, 18)\t1.0\n",
      "(15, 27)\t-1.0\n"
     ]
    }
   ],
   "source": [
    "# Convert the sparse matrix to COO format\n",
    "coo = dh.to_sparse_coo().coalesce()\n",
    "\n",
    "# Print the sparse matrix in the desired format\n",
    "for i, (r, c) in enumerate(coo.indices().T):\n",
    "    print(f\"({r.item()}, {c.item()})\\t{coo.values()[i].item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:52:56.101199800Z",
     "start_time": "2023-06-04T12:52:56.033816500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n          0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n          0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n          0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n          0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n          0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n          0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n          0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n          1.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n          0.,  1.],\n        [-0., -0., -0., -0., -0., -0., -0., -1., -0., -0., -0., -0., -0., -0.,\n         -0., -0.],\n        [-0., -0., -0., -0., -0., -0., -0., -0., -1., -0., -0., -0., -0., -0.,\n         -0., -0.],\n        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -1., -0., -0., -0., -0.,\n         -0., -0.],\n        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -1., -0., -0., -0.,\n         -0., -0.],\n        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -1., -0., -0.,\n         -0., -0.],\n        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -1., -0.,\n         -0., -0.],\n        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -1.,\n         -0., -0.],\n        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n         -1., -0.],\n        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n         -0., -1.]], dtype=torch.float64)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:52:58.670777200Z",
     "start_time": "2023-06-04T12:52:58.574480500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iteration loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max it: 150; i: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type ComplexDouble but found Double",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 15\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hess_fcn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpips: Hessian evaluation via finite differences \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     13\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot yet implemented.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mPlease provide \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     14\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myour own hessian evaluation function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 15\u001B[0m     Lxx \u001B[38;5;241m=\u001B[39m \u001B[43mhess_fcn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlmbda\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcost_mult\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     _, _, d2f \u001B[38;5;241m=\u001B[39m f_fcn(x, \u001B[38;5;28;01mTrue\u001B[39;00m)      \u001B[38;5;66;03m# cost\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[4], line 8\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x, lmbda, cost_mult)\u001B[0m\n\u001B[1;32m      6\u001B[0m f_fcn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x, return_hessian\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m: opf_costfcn(x, pack_para, return_hessian)\n\u001B[1;32m      7\u001B[0m gh_fcn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x: opf_consfcn(x, pack_para, Ybus, Yf_on, Yt_on, ppopt, il)\n\u001B[0;32m----> 8\u001B[0m hess_fcn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x, lmbda, cost_mult: \u001B[43mopf_hessfcn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlmbda\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpack_para\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mYbus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mYf_on\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mYt_on\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mppopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mil\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcost_mult\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/MPP_Powersystem/pypower_pych_gpu/opf_hessfcn.py:183\u001B[0m, in \u001B[0;36mopf_hessfcn\u001B[0;34m(x, lmbda, pack_para, Ybus, Yf, Yt, ppopt, il, cost_mult)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m Yf\u001B[38;5;241m.\u001B[39msize:\n\u001B[1;32m    182\u001B[0m     dIf_dVa, dIf_dVm, dIt_dVa, dIt_dVm, If, It \u001B[38;5;241m=\u001B[39m dIbr_dV(branch, Yf, Yt, V)\n\u001B[0;32m--> 183\u001B[0m     Hfaa, Hfav, Hfva, Hfvv \u001B[38;5;241m=\u001B[39m \u001B[43md2AIbr_dV2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdIf_dVa\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdIf_dVm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mYf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mV\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmuF\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    184\u001B[0m     Htaa, Htav, Htva, Htvv \u001B[38;5;241m=\u001B[39m d2AIbr_dV2(dIt_dVa, dIt_dVm, It, Yt, V, muT)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/MPP_Powersystem/pypower_pych_gpu/d2AIbr_dV2.py:47\u001B[0m, in \u001B[0;36md2AIbr_dV2\u001B[0;34m(dIbr_dVa, dIbr_dVm, Ibr, Ybr, V, lam)\u001B[0m\n\u001B[1;32m     45\u001B[0m Hva \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m ( Iva \u001B[38;5;241m+\u001B[39m dIbr_dVm\u001B[38;5;241m.\u001B[39mt()\u001B[38;5;241m.\u001B[39mmatmul(diaglam\u001B[38;5;241m.\u001B[39mmatmul(dIbr_dVa\u001B[38;5;241m.\u001B[39mconj()) ))\u001B[38;5;241m.\u001B[39mto_dense()\u001B[38;5;241m.\u001B[39mreal\n\u001B[1;32m     46\u001B[0m Hav \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m ( Iav \u001B[38;5;241m+\u001B[39m dIbr_dVa\u001B[38;5;241m.\u001B[39mt()\u001B[38;5;241m.\u001B[39mmatmul(diaglam\u001B[38;5;241m.\u001B[39mmatmul(dIbr_dVm\u001B[38;5;241m.\u001B[39mconj())) )\u001B[38;5;241m.\u001B[39mto_dense()\u001B[38;5;241m.\u001B[39mreal\n\u001B[0;32m---> 47\u001B[0m Hvv \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m ( \u001B[43mIvv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdIbr_dVm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdiaglam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdIbr_dVm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconj\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39mto_dense()\u001B[38;5;241m.\u001B[39mreal\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Haa, Hav, Hva, Hvv\n",
      "\u001B[0;31mRuntimeError\u001B[0m: expected scalar type ComplexDouble but found Double"
     ]
    }
   ],
   "source": [
    "# do Newton iterations\n",
    "while (not converged) and (i < opt[\"max_it\"]):\n",
    "    # update iteration counter\n",
    "    i += 1\n",
    "    print(f\"max it: {opt['max_it']}; i: {i}\")\n",
    "\n",
    "    # compute update step\n",
    "    lmbda = {\"eqnonlin\": lam[range(neqnln)],\n",
    "             \"ineqnonlin\": mu[range(niqnln)]}\n",
    "    if nonlinear:\n",
    "        if hess_fcn is None:\n",
    "            print(\"pips: Hessian evaluation via finite differences \"\n",
    "                  \"not yet implemented.\\nPlease provide \"\n",
    "                  \"your own hessian evaluation function.\")\n",
    "        Lxx = hess_fcn(x, lmbda, opt[\"cost_mult\"])\n",
    "    else:\n",
    "        _, _, d2f = f_fcn(x, True)      # cost\n",
    "        Lxx = d2f * opt[\"cost_mult\"]\n",
    "    rz = arange(len(z))\n",
    "    zinvdiag = sparse((1.0 / z, (rz, rz))) if len(z) else None\n",
    "    rmu = arange(len(mu))\n",
    "    mudiag = sparse((mu, (rmu, rmu))) if len(mu) else None\n",
    "    dh_zinv = None if dh is None else dh.matmul(zinvdiag)\n",
    "    M = Lxx if dh is None else Lxx + dh_zinv.matmul(mudiag).matmul(dh.T)\n",
    "    N = Lx if dh is None else Lx + dh_zinv.matmul((mudiag.matmul(h.to(torch.float64)) + gamma*e))\n",
    "\n",
    "    Ab = M.to_sparse_csr if dg is None else vstack([\n",
    "        hstack([M, dg]),\n",
    "        hstack([dg.T, zeros((neq, neq), dtype=torch.float64)])\n",
    "    ])\n",
    "    bb = cat([-N, -g])\n",
    "\n",
    "    dxdlam = solve(Ab.to_dense(), bb).double()\n",
    "\n",
    "    if any(isnan(dxdlam)):\n",
    "        if opt[\"verbose\"]:\n",
    "            print('\\nNumerically Failed\\n')\n",
    "        eflag = -1\n",
    "        break\n",
    "\n",
    "    dx = dxdlam[:nx]\n",
    "    dlam = dxdlam[nx:nx + neq]\n",
    "    dz = -h - z if dh is None else -h.to(torch.float64) - z - dh.T.matmul(dx)\n",
    "    dmu = -mu if dh is None else -mu + zinvdiag.matmul( (gamma * e - mudiag.matmul(dz)))\n",
    "\n",
    "    # do the update\n",
    "    k = find(dz < 0.0)\n",
    "    alphap = min([xi * min(z[k] / -dz[k]), 1]) if len(k) else 1.0\n",
    "    k = find(dmu < 0.0)\n",
    "    alphad = min([xi * min(mu[k] / -dmu[k]), 1]) if len(k) else 1.0\n",
    "    x = x + alphap * dx\n",
    "    z = z + alphap * dz\n",
    "    lam = lam + alphad * dlam\n",
    "    mu = mu + alphad * dmu\n",
    "    if niq > 0:\n",
    "        gamma = sigma * dot(z, mu) / niq\n",
    "\n",
    "    # evaluate cost, constraints, derivatives\n",
    "    f, df = f_fcn(x)             # cost\n",
    "    f = f * opt[\"cost_mult\"]\n",
    "    df = df * opt[\"cost_mult\"]\n",
    "    if nonlinear:\n",
    "        hn, gn, dhn, dgn = gh_fcn(x)                   # nln constraints\n",
    "#            g = gn if Ai is None else r_[gn, Ai * x - bi] # ieq constraints\n",
    "#            h = hn if Ae is None else r_[hn, Ae * x - be] # eq constraints\n",
    "        h = hn if Ai is None else cat([hn, Ai.to(torch.float64).matmul(x) - bi])  # inequality constraints\n",
    "        g = gn if Ae is None else cat([gn, Ae.to(torch.float64).matmul(x) - be])\n",
    "        # h = hn if Ai is None else cat([hn.reshape(len(hn),), Ai * x - bi]) # ieq constr\n",
    "        # g = gn if Ae is None else cat([gn, Ae * x - be])  # eq constr\n",
    "\n",
    "        if (dhn is None) and (Ai is None):\n",
    "            dh = None\n",
    "        elif dhn is None:\n",
    "            dh = Ai.T\n",
    "        elif Ai is None:\n",
    "            dh = dhn\n",
    "        else:\n",
    "            dh = hstack([dhn, Ai.T])\n",
    "\n",
    "        if (dgn is None) and (Ae is None):\n",
    "            dg = None\n",
    "        elif dgn is None:\n",
    "            dg = Ae.T\n",
    "        elif Ae is None:\n",
    "            dg = dgn\n",
    "        else:\n",
    "            dg = hstack([dgn, Ae.T])\n",
    "    else:\n",
    "        h = -bi if Ai is None else Ai.matmul(x) - bi    # inequality constraints\n",
    "        g = -be if Ae is None else Ae.matmul(x) - be    # equality constraints\n",
    "        # 1st derivatives are constant, still dh = Ai.T, dg = Ae.T\n",
    "\n",
    "    Lx = df\n",
    "    Lx = Lx + dg.matmul(lam) if dg is not None else Lx\n",
    "    Lx = Lx + dh.matmul(mu)  if dh is not None else Lx\n",
    "\n",
    "    if len(h) == 0:\n",
    "        maxh = zeros(1)\n",
    "    else:\n",
    "        maxh = max(h)\n",
    "\n",
    "    gnorm = norm(g, Inf) if len(g) else 0.0\n",
    "    lam_norm = norm(lam, Inf) if len(lam) else 0.0\n",
    "    mu_norm = norm(mu, Inf) if len(mu) else 0.0\n",
    "    znorm = norm(z, Inf) if len(z) else 0.0\n",
    "    feascond = \\\n",
    "        max([gnorm, maxh]) / (1 + max([norm(x, Inf), znorm]))\n",
    "    gradcond = \\\n",
    "        norm(Lx, Inf) / (1 + max([lam_norm, mu_norm]))\n",
    "    compcond = dot(z, mu) / (1 + norm(x, Inf))\n",
    "    costcond = float(absolute(f - f0) / (1 + absolute(f0)))\n",
    "\n",
    "    hist.append({'feascond': feascond, 'gradcond': gradcond,\n",
    "        'compcond': compcond, 'costcond': costcond, 'gamma': gamma,\n",
    "        'stepsize': norm(dx), 'obj': f / opt[\"cost_mult\"],\n",
    "        'alphap': alphap, 'alphad': alphad})\n",
    "\n",
    "    if opt[\"verbose\"] > 1:\n",
    "        print(\"%3d  %12.8g %10.5g %12g %12g %12g %12g\" %\n",
    "            (i, (f / opt[\"cost_mult\"]), norm(dx), feascond, gradcond,\n",
    "             compcond, costcond))\n",
    "\n",
    "    if feascond < opt[\"feastol\"] and gradcond < opt[\"gradtol\"] and \\\n",
    "        compcond < opt[\"comptol\"] and costcond < opt[\"costtol\"]:\n",
    "        converged = True\n",
    "        if opt[\"verbose\"]:\n",
    "            print(\"Converged!\")\n",
    "    else: #TODO alpha and alphad are too small\n",
    "        if any(isnan(x)) or (alphap < alpha_min) or \\\n",
    "            (alphad < alpha_min) or (gamma < EPS) or (gamma > 1.0 / EPS):\n",
    "            if opt[\"verbose\"]:\n",
    "                print(\"Numerically failed.\")\n",
    "            eflag = -1\n",
    "            break\n",
    "        f0 = f\n",
    "\n",
    "        if opt[\"step_control\"]:\n",
    "            L = f + dot(lam, g) + dot(mu, (h + z)) - gamma * sum(log(z))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T11:07:57.153104600Z",
     "start_time": "2023-06-05T11:07:55.958914900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lxx: tensor([[ 6.0829e+05, -6.0829e+05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -5.1728e-12,  1.1710e-11,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [-6.0829e+05,  9.5812e+05, -3.4982e+05,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  6.1959e-12, -3.5811e-12, -9.0949e-12,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00, -3.4982e+05,  1.2790e+06, -3.4982e+05,  0.0000e+00,\n",
      "         -5.7933e+05,  0.0000e+00, -9.0949e-12,  1.2108e-11, -9.0949e-12,\n",
      "          0.0000e+00,  6.1959e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.4982e+05,  6.9965e+05, -3.4982e+05,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -9.0949e-12,  1.8253e-11,\n",
      "         -9.0949e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4982e+05,  3.4982e+05,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.0949e-12,\n",
      "          9.0949e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -5.7933e+05,  0.0000e+00,  0.0000e+00,\n",
      "          5.7933e+05,  0.0000e+00,  0.0000e+00,  6.1959e-12,  0.0000e+00,\n",
      "          0.0000e+00, -6.1959e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [-5.1728e-12,  6.1959e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  5.7933e+05, -5.7933e+05,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 1.1710e-11, -3.5811e-12, -9.0949e-12,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -5.7933e+05,  9.2916e+05, -3.4982e+05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00, -9.0949e-12,  1.2108e-11, -9.0949e-12,  0.0000e+00,\n",
      "          6.1959e-12,  0.0000e+00, -3.4982e+05,  1.2790e+06, -3.4982e+05,\n",
      "          0.0000e+00, -5.7933e+05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -9.0949e-12,  1.8253e-11, -9.0949e-12,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4982e+05,  6.9966e+05,\n",
      "         -3.4982e+05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -9.0949e-12,  9.0949e-12,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4982e+05,\n",
      "          3.4983e+05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  6.1959e-12,  0.0000e+00,  0.0000e+00,\n",
      "         -6.1959e-12,  0.0000e+00,  0.0000e+00, -5.7933e+05,  0.0000e+00,\n",
      "          0.0000e+00,  5.7933e+05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lxx: {Lxx}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T07:01:38.526864300Z",
     "start_time": "2023-06-04T07:01:38.431896Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dxdlam:tensor([ 1.0625e-17, -1.0842e-02,  9.0286e-03, -8.8349e-02, -1.3601e-01,\n",
      "        -2.7796e-02,  4.0629e-15,  2.2318e-02, -8.7540e-03, -3.9595e-02,\n",
      "        -5.7197e-02, -2.2954e-02, -4.9134e+02,  6.3846e+00,  6.8734e+00,\n",
      "        -2.0122e+01,  1.8035e+01,  1.6087e+01,  1.0319e+01,  1.2953e+02,\n",
      "         1.8916e+02,  7.0142e+01,  1.3747e-08, -4.2665e+01, -4.0244e-08,\n",
      "        -1.6770e+01, -2.2253e+01, -4.4564e+00,  1.6526e-04, -1.1539e+03])\n"
     ]
    }
   ],
   "source": [
    "print(f\"dxdlam:{dxdlam}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T07:09:00.854267200Z",
     "start_time": "2023-06-04T07:09:00.727903800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\t608334.4586080383\n",
      "(0, 1)\t-608334.4586080384\n",
      "(0, 6)\t-95.61320495605986\n",
      "(0, 7)\t91.44357299805858\n",
      "(0, 16)\t361.701416015625\n",
      "(0, 17)\t-361.701416015625\n",
      "(0, 22)\t-171.14651489257812\n",
      "(0, 23)\t171.14651489257812\n",
      "(0, 28)\t1.0\n",
      "(1, 0)\t-608334.4586080384\n",
      "(1, 1)\t958193.5279525565\n",
      "(1, 2)\t-349859.0693445183\n",
      "(1, 6)\t95.61320495606088\n",
      "(1, 7)\t-167.17160034180046\n",
      "(1, 8)\t75.72801208495184\n",
      "(1, 16)\t-361.701416015625\n",
      "(1, 17)\t629.6283569335938\n",
      "(1, 18)\t-267.9269714355469\n",
      "(1, 22)\t171.14651489257812\n",
      "(1, 23)\t-297.9217224121094\n",
      "(1, 24)\t126.77519989013672\n",
      "(2, 1)\t-349859.0693445183\n",
      "(2, 2)\t1279080.7074834527\n",
      "(2, 3)\t-349859.0693445183\n",
      "(2, 5)\t-579362.5687906015\n",
      "(2, 7)\t75.72801208495184\n",
      "(2, 8)\t-227.2594757079957\n",
      "(2, 9)\t75.72801208495184\n",
      "(2, 11)\t75.8034439086976\n",
      "(2, 17)\t-267.9269714355469\n",
      "(2, 18)\t880.3314819335938\n",
      "(2, 19)\t-267.9269714355469\n",
      "(2, 21)\t-344.4775390625\n",
      "(2, 23)\t126.77519989013672\n",
      "(2, 24)\t-416.5470886230469\n",
      "(2, 25)\t126.77519989013672\n",
      "(2, 27)\t162.99668884277344\n",
      "(3, 2)\t-349859.0693445183\n",
      "(3, 3)\t699718.1386890366\n",
      "(3, 4)\t-349859.0693445183\n",
      "(3, 8)\t75.72801208495184\n",
      "(3, 9)\t-151.45602416990363\n",
      "(3, 10)\t75.72801208495184\n",
      "(3, 18)\t-267.9269714355469\n",
      "(3, 19)\t535.8539428710938\n",
      "(3, 20)\t-267.9269714355469\n",
      "(3, 24)\t126.77519989013672\n",
      "(3, 25)\t-253.55039978027344\n",
      "(3, 26)\t126.77519989013672\n",
      "(4, 3)\t-349859.0693445183\n",
      "(4, 4)\t349859.0693445183\n",
      "(4, 9)\t75.72801208495184\n",
      "(4, 10)\t-75.72801208495184\n",
      "(4, 19)\t-267.9269714355469\n",
      "(4, 20)\t267.9269714355469\n",
      "(4, 25)\t126.77519989013672\n",
      "(4, 26)\t-126.77519989013672\n",
      "(5, 2)\t-579362.5687906015\n",
      "(5, 5)\t579362.5687906013\n",
      "(5, 8)\t75.80343627930307\n",
      "(5, 11)\t-75.8034439086976\n",
      "(5, 18)\t-344.4775390625\n",
      "(5, 21)\t344.4775390625\n",
      "(5, 24)\t162.99668884277344\n",
      "(5, 27)\t-162.99668884277344\n",
      "(6, 0)\t-95.61313629150908\n",
      "(6, 1)\t95.6131362915101\n",
      "(6, 6)\t634363.2373531224\n",
      "(6, 7)\t-634340.4018327462\n",
      "(6, 16)\t179.29635620117188\n",
      "(6, 17)\t-162.99668884277344\n",
      "(6, 22)\t376.4805603027344\n",
      "(6, 23)\t-344.4775390625\n",
      "(6, 29)\t1.0\n",
      "(7, 0)\t91.44355773926952\n",
      "(7, 1)\t-167.1715850830114\n",
      "(7, 2)\t75.72801971434637\n",
      "(7, 6)\t-634340.3979264962\n",
      "(7, 7)\t984312.6242373178\n",
      "(7, 8)\t-349982.73215579754\n",
      "(7, 16)\t-171.14651489257812\n",
      "(7, 17)\t281.6220397949219\n",
      "(7, 18)\t-126.77519989013672\n",
      "(7, 22)\t-361.701416015625\n",
      "(7, 23)\t589.8587646484375\n",
      "(7, 24)\t-267.9269714355469\n",
      "(8, 1)\t75.72801208495184\n",
      "(8, 2)\t-227.2594757079957\n",
      "(8, 3)\t75.72801971434637\n",
      "(8, 5)\t75.8034439086976\n",
      "(8, 7)\t-349982.73215579754\n",
      "(8, 8)\t1279465.7141549606\n",
      "(8, 9)\t-349982.73215579754\n",
      "(8, 11)\t-579486.5721055734\n",
      "(8, 17)\t-126.77519989013672\n",
      "(8, 18)\t416.5470886230469\n",
      "(8, 19)\t-126.77519989013672\n",
      "(8, 21)\t-162.99668884277344\n",
      "(8, 23)\t-267.9269714355469\n",
      "(8, 24)\t872.0160522460938\n",
      "(8, 25)\t-267.9269714355469\n",
      "(8, 27)\t-344.4775390625\n",
      "(9, 2)\t75.72801208495184\n",
      "(9, 3)\t-151.4560394286927\n",
      "(9, 4)\t75.72801971434637\n",
      "(9, 8)\t-349982.73215579754\n",
      "(9, 9)\t699976.4306287423\n",
      "(9, 10)\t-349982.73215579754\n",
      "(9, 18)\t-126.77519989013672\n",
      "(9, 19)\t253.55039978027344\n",
      "(9, 20)\t-126.77519989013672\n",
      "(9, 24)\t-267.9269714355469\n",
      "(9, 25)\t529.8668212890625\n",
      "(9, 26)\t-267.9269714355469\n",
      "(10, 3)\t75.72801208495184\n",
      "(10, 4)\t-75.72801208495184\n",
      "(10, 9)\t-349982.73215579754\n",
      "(10, 10)\t349989.21531437116\n",
      "(10, 19)\t-126.77519989013672\n",
      "(10, 20)\t126.77519989013672\n",
      "(10, 25)\t-267.9269714355469\n",
      "(10, 26)\t264.93341064453125\n",
      "(11, 2)\t75.80343627930307\n",
      "(11, 5)\t-75.80343627930307\n",
      "(11, 8)\t-579486.5721055734\n",
      "(11, 11)\t579491.2835414769\n",
      "(11, 18)\t-162.99668884277344\n",
      "(11, 21)\t162.99668884277344\n",
      "(11, 24)\t-344.4775390625\n",
      "(11, 27)\t342.1492004394531\n",
      "(12, 12)\t0.004000000189989805\n",
      "(12, 16)\t-1.0\n",
      "(13, 13)\t0.05000000074505806\n",
      "(13, 18)\t-1.0\n",
      "(14, 14)\t1.999999943436137e-09\n",
      "(14, 22)\t-1.0\n",
      "(15, 15)\t1.999999943436137e-09\n",
      "(15, 24)\t-1.0\n",
      "(16, 0)\t361.701416015625\n",
      "(16, 1)\t-361.701416015625\n",
      "(16, 6)\t179.29635620117188\n",
      "(16, 7)\t-171.14651489257812\n",
      "(16, 12)\t-1.0\n",
      "(17, 0)\t-361.701416015625\n",
      "(17, 1)\t629.6283569335938\n",
      "(17, 2)\t-267.9269714355469\n",
      "(17, 6)\t-162.99668884277344\n",
      "(17, 7)\t281.6220397949219\n",
      "(17, 8)\t-126.77519989013672\n",
      "(18, 1)\t-267.9269714355469\n",
      "(18, 2)\t880.3314819335938\n",
      "(18, 3)\t-267.9269714355469\n",
      "(18, 5)\t-344.4775390625\n",
      "(18, 7)\t-126.77519989013672\n",
      "(18, 8)\t416.5470886230469\n",
      "(18, 9)\t-126.77519989013672\n",
      "(18, 11)\t-162.99668884277344\n",
      "(18, 13)\t-1.0\n",
      "(19, 2)\t-267.9269714355469\n",
      "(19, 3)\t535.8539428710938\n",
      "(19, 4)\t-267.9269714355469\n",
      "(19, 8)\t-126.77519989013672\n",
      "(19, 9)\t253.55039978027344\n",
      "(19, 10)\t-126.77519989013672\n",
      "(20, 3)\t-267.9269714355469\n",
      "(20, 4)\t267.9269714355469\n",
      "(20, 9)\t-126.77519989013672\n",
      "(20, 10)\t126.77519989013672\n",
      "(21, 2)\t-344.4775390625\n",
      "(21, 5)\t344.4775390625\n",
      "(21, 8)\t-162.99668884277344\n",
      "(21, 11)\t162.99668884277344\n",
      "(22, 0)\t-171.14651489257812\n",
      "(22, 1)\t171.14651489257812\n",
      "(22, 6)\t376.4805603027344\n",
      "(22, 7)\t-361.701416015625\n",
      "(22, 14)\t-1.0\n",
      "(23, 0)\t171.14651489257812\n",
      "(23, 1)\t-297.9217224121094\n",
      "(23, 2)\t126.77519989013672\n",
      "(23, 6)\t-344.4775390625\n",
      "(23, 7)\t589.8587646484375\n",
      "(23, 8)\t-267.9269714355469\n",
      "(24, 1)\t126.77519989013672\n",
      "(24, 2)\t-416.5470886230469\n",
      "(24, 3)\t126.77519989013672\n",
      "(24, 5)\t162.99668884277344\n",
      "(24, 7)\t-267.9269714355469\n",
      "(24, 8)\t872.0160522460938\n",
      "(24, 9)\t-267.9269714355469\n",
      "(24, 11)\t-344.4775390625\n",
      "(24, 15)\t-1.0\n",
      "(25, 2)\t126.77519989013672\n",
      "(25, 3)\t-253.55039978027344\n",
      "(25, 4)\t126.77519989013672\n",
      "(25, 8)\t-267.9269714355469\n",
      "(25, 9)\t529.8668212890625\n",
      "(25, 10)\t-267.9269714355469\n",
      "(26, 3)\t126.77519989013672\n",
      "(26, 4)\t-126.77519989013672\n",
      "(26, 9)\t-267.9269714355469\n",
      "(26, 10)\t264.93341064453125\n",
      "(27, 2)\t162.99668884277344\n",
      "(27, 5)\t-162.99668884277344\n",
      "(27, 8)\t-344.4775390625\n",
      "(27, 11)\t342.1492004394531\n",
      "(28, 0)\t1.0\n",
      "(29, 6)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Ab:{Ab.to_sparse_csr()}\\nbb:{bb}\")\n",
    "# Convert the sparse matrix to COO format\n",
    "coo = Ab.T.to_sparse_coo().coalesce()\n",
    "\n",
    "# Print the sparse matrix in the desired format\n",
    "for i, (r, c) in enumerate(coo.indices().T):\n",
    "    print(f\"({r.item()}, {c.item()})\\t{coo.values()[i].item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T07:21:21.984271400Z",
     "start_time": "2023-06-04T07:21:21.924430800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([30, 30])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ab.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T07:20:39.182062400Z",
     "start_time": "2023-06-04T07:20:39.176078100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 5.4932e-04, -5.4932e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n        -0.0000e+00, -3.7871e+00,  3.7852e+00, -1.4257e-03, -1.1206e-03,\n        -5.7125e-04, -3.8815e-04, -2.0000e+01, -1.0000e+01, -0.0000e+00,\n        -0.0000e+00,  4.9144e+02, -1.8502e+00,  4.0000e+01, -1.5000e+01,\n        -1.5000e+01, -1.5000e+01, -1.6802e+01,  1.9885e+01,  4.1577e+00,\n         2.9935e+00,  1.4968e+00,  1.1642e+00, -0.0000e+00, -0.0000e+00],\n       dtype=torch.float64)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T07:25:37.690588500Z",
     "start_time": "2023-06-04T07:25:37.601827300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-4.2607e+03,  4.4650e+03, -2.9238e+02,  3.0037e+02, -3.7525e+02,\n         1.6303e+02,  2.6763e+07, -2.6754e+07,  9.5632e+03,  6.9665e+03,\n         3.4467e+03,  2.1676e+03,  7.9713e+00,  5.2640e+00, -6.9401e-09,\n         2.0317e-08])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lx + dh_zinv.matmul((mudiag.matmul(h.to(torch.float64)) + gamma*e))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T08:03:03.777143200Z",
     "start_time": "2023-06-04T08:03:03.702343800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-3.1543e+02,  5.2274e+02, -2.9670e+02,  3.0112e+02, -3.7497e+02,\n         1.6325e+02,  1.4931e+04, -1.5603e+04, -7.1576e+02, -9.3400e+02,\n        -5.0326e+02, -2.2190e+02,  9.9030e+00,  4.9515e+00, -6.9401e-09,\n         2.0317e-08])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T08:10:28.033135100Z",
     "start_time": "2023-06-04T08:10:27.982051500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-3.9453e+03,  3.9423e+03,  4.3125e+00, -7.5000e-01, -2.8125e-01,\n        -2.1875e-01,  2.6748e+07, -2.6738e+07,  1.0279e+04,  7.9005e+03,\n         3.9500e+03,  2.3895e+03, -1.9316e+00,  3.1250e-01,  0.0000e+00,\n         0.0000e+00])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh_zinv.matmul((mudiag.matmul(h.to(torch.float64)) + gamma*e))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T08:12:46.390522600Z",
     "start_time": "2023-06-04T08:12:46.272837400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 371.4802, -367.7521,    0.0000,    0.0000,    0.0000,    0.0000,\n         -170.9520,  178.8311,    0.0000,    0.0000,    0.0000,    0.0000,\n            1.0000,    0.0000],\n        [-371.4802,  636.6406, -273.9060,    0.0000,    0.0000,    0.0000,\n          170.9520, -312.5503,  123.1152,    0.0000,    0.0000,    0.0000,\n            0.0000,    0.0000],\n        [   0.0000, -268.8885,  878.8698, -242.5683,    0.0000, -327.8716,\n            0.0000,  133.7193, -364.7171,  144.6392,    0.0000,  169.9256,\n            0.0000,    0.0000],\n        [   0.0000,    0.0000, -265.6591,  490.7067, -237.3682,    0.0000,\n            0.0000,    0.0000,   95.8391, -248.1220,  126.2447,    0.0000,\n            0.0000,    0.0000],\n        [   0.0000,    0.0000,    0.0000, -248.1384,  237.3682,    0.0000,\n            0.0000,    0.0000,    0.0000,  103.4828, -126.2447,    0.0000,\n            0.0000,    0.0000],\n        [   0.0000,    0.0000, -339.3047,    0.0000,    0.0000,  327.8716,\n            0.0000,    0.0000,  145.7628,    0.0000,    0.0000, -169.9256,\n            0.0000,    0.0000],\n        [ 179.4816, -170.3153,    0.0000,    0.0000,    0.0000,    0.0000,\n          367.1674, -350.2401,    0.0000,    0.0000,    0.0000,    0.0000,\n            0.0000,    1.0000],\n        [-167.2819,  286.4188, -120.4721,    0.0000,    0.0000,    0.0000,\n         -363.5049,  623.2702, -268.0255,    0.0000,    0.0000,    0.0000,\n            0.0000,    0.0000],\n        [   0.0000, -134.8800,  458.0420, -145.8947,    0.0000, -171.4006,\n            0.0000, -271.2225,  850.7690, -244.6738,    0.0000, -330.7176,\n            0.0000,    0.0000],\n        [   0.0000,    0.0000,  -99.7205,  229.1918, -131.3576,    0.0000,\n            0.0000,    0.0000, -276.4182,  513.6591, -246.9815,    0.0000,\n            0.0000,    0.0000],\n        [   0.0000,    0.0000,    0.0000, -109.6480,  105.5280,    0.0000,\n            0.0000,    0.0000,    0.0000, -262.9218,  251.3893,    0.0000,\n            0.0000,    0.0000],\n        [   0.0000,    0.0000, -149.1278,    0.0000,    0.0000,  144.7889,\n            0.0000,    0.0000, -347.1379,    0.0000,    0.0000,  335.6922,\n            0.0000,    0.0000],\n        [  -1.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n            0.0000,    0.0000],\n        [   0.0000,    0.0000,   -1.0000,    0.0000,    0.0000,    0.0000,\n            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n            0.0000,    0.0000],\n        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n           -1.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n            0.0000,    0.0000],\n        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n            0.0000,    0.0000,   -1.0000,    0.0000,    0.0000,    0.0000,\n            0.0000,    0.0000]])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T08:20:43.793395900Z",
     "start_time": "2023-06-04T08:20:43.723582100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\t3719.8564453125\n",
      "(0, 8)\t2905.451904296875\n",
      "(1, 2)\t-3076.91064453125\n",
      "(1, 3)\t-3719.8564453125\n",
      "(1, 7)\t-3845.75634765625\n",
      "(1, 8)\t-2905.451904296875\n",
      "(2, 1)\t16289.1103515625\n",
      "(2, 2)\t3076.91064453125\n",
      "(2, 4)\t9791.4658203125\n",
      "(2, 6)\t15569.2275390625\n",
      "(2, 7)\t3845.75634765625\n",
      "(2, 9)\t10526.4873046875\n",
      "(3, 0)\t7773.71533203125\n",
      "(3, 1)\t-16289.1103515625\n",
      "(3, 5)\t7086.015625\n",
      "(3, 6)\t-15569.2275390625\n",
      "(4, 0)\t-7773.71533203125\n",
      "(4, 5)\t-7086.015625\n",
      "(5, 4)\t-9791.4658203125\n",
      "(5, 9)\t-10526.4873046875\n",
      "(6, 3)\t7309.56982421875\n",
      "(6, 8)\t8982.7646484375\n",
      "(7, 2)\t4553.4462890625\n",
      "(7, 3)\t-7286.76171875\n",
      "(7, 7)\t6202.8623046875\n",
      "(7, 8)\t-8931.783203125\n",
      "(7, 10)\t1.0\n",
      "(7, 19)\t-1.0\n",
      "(8, 1)\t5316.720703125\n",
      "(8, 2)\t-4521.10888671875\n",
      "(8, 4)\t5010.76025390625\n",
      "(8, 6)\t6832.85400390625\n",
      "(8, 7)\t-6091.81494140625\n",
      "(8, 9)\t3449.999755859375\n",
      "(8, 11)\t1.0\n",
      "(8, 20)\t-1.0\n",
      "(9, 0)\t2458.002197265625\n",
      "(9, 1)\t-3702.2333984375\n",
      "(9, 5)\t3961.814697265625\n",
      "(9, 6)\t-5311.51611328125\n",
      "(9, 12)\t1.0\n",
      "(9, 21)\t-1.0\n",
      "(10, 0)\t-2068.157470703125\n",
      "(10, 5)\t-3611.999755859375\n",
      "(10, 13)\t1.0\n",
      "(10, 22)\t-1.0\n",
      "(11, 4)\t-4650.3134765625\n",
      "(11, 9)\t-3057.822021484375\n",
      "(11, 14)\t1.0\n",
      "(11, 23)\t-1.0\n",
      "(12, 15)\t1.0\n",
      "(12, 24)\t-1.0\n",
      "(13, 16)\t1.0\n",
      "(13, 25)\t-1.0\n",
      "(14, 17)\t1.0\n",
      "(14, 26)\t-1.0\n",
      "(15, 18)\t1.0\n",
      "(15, 27)\t-1.0\n"
     ]
    }
   ],
   "source": [
    "coo = dh.to_sparse_coo().coalesce()\n",
    "\n",
    "# Print the sparse matrix in the desired format\n",
    "for i, (r, c) in enumerate(coo.indices().T):\n",
    "    print(f\"({r.item()}, {c.item()})\\t{coo.values()[i].item()}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T11:29:06.676328Z",
     "start_time": "2023-06-04T11:29:06.615154400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "nvenv",
   "language": "python",
   "display_name": "nvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
