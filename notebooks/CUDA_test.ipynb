{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "import sys, os\n",
    "path_current = '/home/huzuntao/PycharmProjects/MPP_Powersystem/'\n",
    "path_ = os.getcwd()\n",
    "if path_current not in sys.path:\n",
    "    sys.path.insert(1, '/home/huzuntao/PycharmProjects/MPP_Powersystem/')\n",
    "elif path_ not in sys.path:\n",
    "    sys.path.insert(1, path_)\n",
    "import pandapower as pp\n",
    "from PPOPT_main.PPOPT_main.src.ppopt.mpQCQP_program import MPQCQP_Program"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-03T03:19:45.970244900Z",
     "start_time": "2023-06-03T03:19:32.123206400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0.],\n        [0., 0.],\n        [0., 1.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import tensor, ones, arange\n",
    "\n",
    "def sparse(*args, **kwargs):\n",
    "    if len(args) == 1: # sparse((values, crow_ccol))\n",
    "        values, crow_ccol = args[0]\n",
    "    elif len(args) == 2: # sparse(values, crow_ccol)\n",
    "        if len(args[0]) != 2 and (not isinstance(args[1][0], int)):\n",
    "            values, crow_ccol = args[0], args[1]\n",
    "        else:\n",
    "            return torch.sparse_coo_tensor(args[0][1],\n",
    "                                           values=args[0][0], size=args[1]\n",
    "                                           ).to_sparse(layout=torch.sparse_csr)\n",
    "    else:\n",
    "        raise ValueError(\"sparse() takes 1 or 2 positional arguments but {} were given\".format(len(args)))\n",
    "\n",
    "    # crow = crow_ccol[0]\n",
    "    # ccol = crow_ccol[1]\n",
    "\n",
    "    return torch.sparse_coo_tensor(crow_ccol, values, (max(crow_ccol[0])+1, max(crow_ccol[1])+1)).to_sparse(layout=torch.sparse_csr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gen = tensor([[500.-0.j,  40.-0.j]], dtype=torch.complex128)\n",
    "nb = 6\n",
    "ngon = 2\n",
    "gbus = [0,2]\n",
    "## connection matrix, element i, j is 1 if gen on(j) at bus i is ON\n",
    "Cg = sparse((ones(ngon), (gbus, arange(ngon))), (nb, ngon))\n",
    "\n",
    "Cg = torch.sparse_coo_tensor([gbus, list(range(ngon))], values=ones(ngon), size=(nb, ngon)).to_sparse(layout=torch.sparse_csr)\n",
    "Cg.to_dense()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:09:04.554263800Z",
     "start_time": "2023-06-03T07:09:04.514371700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0.],\n       [0., 0.],\n       [0., 1.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "csr_matrix((ones(ngon), (gbus, arange(ngon))), (nb, ngon)).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T03:40:01.920713900Z",
     "start_time": "2023-06-03T03:40:01.842922500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy time: 1.04764 seconds\n",
      "CuPy time: 7.38341 seconds\n"
     ]
    }
   ],
   "source": [
    "# 创建一个5000*5000的随机矩阵\n",
    "size = 5000\n",
    "A_np = np.random.rand(size, size)\n",
    "\n",
    "# 使用numpy求解矩阵的逆\n",
    "start_time = time.time()\n",
    "A_inv_np = np.linalg.inv(A_np)\n",
    "numpy_time = time.time() - start_time\n",
    "print(\"Numpy time: {:.5f} seconds\".format(numpy_time))\n",
    "\n",
    "# 创建一个在GPU上的相同的矩阵\n",
    "A_cp = cp.array(A_np)\n",
    "\n",
    "# 使用cupy求解矩阵的逆\n",
    "start_time = time.time()\n",
    "A_inv_cp = cp.linalg.inv(A_cp)\n",
    "cupy_time = time.time() - start_time\n",
    "print(\"CuPy time: {:.5f} seconds\".format(cupy_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-02T11:18:38.886291100Z",
     "start_time": "2023-06-02T11:18:29.432798500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 0: 0.5000407201853567\n",
      "Array 1: 0.49999926493497654\n",
      "Array 2: 0.5000011522116486\n",
      "Array 3: 0.5000027345254558\n",
      "Array 4: 0.49999722897403165\n",
      "Array 5: 0.49999356236711995\n",
      "Array 6: 0.4999626574009674\n",
      "Array 7: 0.4999982962141725\n",
      "Array 8: 0.5000430950377951\n",
      "Array 9: 0.5000216948573987\n",
      "CuPy time: 1.25657 seconds\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def compute(array):\n",
    "    # 进行某些计算，例如，计算数组的平均值\n",
    "    return cp.mean(array)\n",
    "start_time = time.time()\n",
    "# 创建随机数组列表\n",
    "arrays = [cp.random.rand(10000, 10000) for _ in range(10)]\n",
    "\n",
    "# 使用线程池并发计算数组\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    results = executor.map(compute, arrays)\n",
    "\n",
    "# 输出结果\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Array {i}: {result}\")\n",
    "cupy_time = time.time() - start_time\n",
    "print(\"CuPy time: {:.5f} seconds\".format(cupy_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-02T11:18:40.154908300Z",
     "start_time": "2023-06-02T11:18:38.886291100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 0: 0.5000347623585583\n",
      "Array 1: 0.49999509936487035\n",
      "Array 2: 0.5000061808148327\n",
      "Array 3: 0.5000198488576899\n",
      "Array 4: 0.49998476501677364\n",
      "Array 5: 0.4999975425440861\n",
      "Array 6: 0.499949577621757\n",
      "Array 7: 0.49997838469925576\n",
      "Array 8: 0.4999486261512285\n",
      "Array 9: 0.5000139524684339\n",
      "NumPy time: 8.14746 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def compute(array):\n",
    "    # 进行某些计算，例如，计算数组的平均值\n",
    "    return np.mean(array)\n",
    "\n",
    "start_time = time.time()\n",
    "# 创建随机数组列表\n",
    "arrays = [np.random.rand(10000, 10000) for _ in range(10)]\n",
    "\n",
    "# 使用线程池并发计算数组\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    results = executor.map(compute, arrays)\n",
    "\n",
    "# 输出结果\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Array {i}: {result}\")\n",
    "numpy_time = time.time() - start_time\n",
    "print(\"NumPy time: {:.5f} seconds\".format(numpy_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-02T11:18:48.364180400Z",
     "start_time": "2023-06-02T11:18:40.153909100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n",
      "/home/huzuntao/.conda/envs/nvenv/lib/python3.9/site-packages/pandapower/auxiliary.py:268: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item, dtype in list(dtypes.iteritems()):\n"
     ]
    }
   ],
   "source": [
    "net = pp.create_empty_network()\n",
    "\n",
    "# create buses\n",
    "bus1 = pp.create_bus(net, vn_kv=110.)\n",
    "bus2 = pp.create_bus(net, vn_kv=110.)\n",
    "bus3 = pp.create_bus(net, vn_kv=110.)\n",
    "bus4 = pp.create_bus(net, vn_kv=110.)\n",
    "bus5 = pp.create_bus(net, vn_kv=110.)\n",
    "bus6 = pp.create_bus(net, vn_kv=110.)\n",
    "\n",
    "# create 110 kV lines\n",
    "pp.create_line(net, bus4, bus5, length_km=90., std_type='149-AL1/24-ST1A 110.0')\n",
    "pp.create_line(net, bus3, bus4, length_km=90., std_type='149-AL1/24-ST1A 110.0')\n",
    "pp.create_line(net, bus2, bus3, length_km=90., std_type='149-AL1/24-ST1A 110.0')\n",
    "pp.create_line(net, bus1, bus2, length_km=70., std_type='149-AL1/24-ST1A 110.0')\n",
    "pp.create_line(net, bus6, bus3, length_km=70., std_type='149-AL1/24-ST1A 110.0')\n",
    "\n",
    "# create loads\n",
    "p_load_1 = 10\n",
    "p_load_2 = 30\n",
    "pp.create_load(net, bus2, p_mw=p_load_1, controllable=False)\n",
    "pp.create_load(net, bus4, p_mw=p_load_2/2, controllable=False)\n",
    "pp.create_load(net, bus5, p_mw=p_load_2/2, controllable=False)\n",
    "pp.create_load(net, bus6, p_mw=p_load_2/2, controllable=False)\n",
    "# create generators\n",
    "eg = pp.create_ext_grid(net, bus1, min_p_mw=0, max_p_mw=1000, vm_pu=1.05)\n",
    "g0 = pp.create_gen(net, bus3, p_mw=80, min_p_mw=0, max_p_mw=80, vm_pu=1.00, controllable=True)\n",
    "\n",
    "costeg = pp.create_poly_cost(net, 0, 'ext_grid', cp1_eur_per_mw=20)\n",
    "costgen1 = pp.create_poly_cost(net, 0, 'gen', cp1_eur_per_mw=10)\n",
    "costgen2 = pp.create_poly_cost(net, 1, 'gen', cp1_eur_per_mw=10)\n",
    "\n",
    "net.bus[\"min_vm_pu\"] = 0.96\n",
    "net.bus[\"max_vm_pu\"] = 1.04\n",
    "net.line[\"max_loading_percent\"] = 100\n",
    "om, ppopt, raw = pp.runopp(net, delta=1e-16, RETURN_RAW_DER=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-02T11:18:50.148466300Z",
     "start_time": "2023-06-02T11:18:48.339565200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creating COO sparse matrix with numpy...\n",
      "Time for creating COO sparse matrix with numpy: 0.00128s\n",
      "Start creating COO sparse matrix with cupy...\n",
      "Time for creating COO sparse matrix with cupy: 1.77718s\n",
      "Start matrix multiplication with numpy...\n",
      "Time for computing operations on sparse matrix with numpy: 0.00212s\n",
      "Start matrix multiplication with cupy...\n",
      "Time for computing operations on sparse matrix with cupy: 0.00721s\n",
      "Ratio of computation time(numpy/cupy): 0.29358\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# 随机生成稀疏矩阵\n",
    "n = 10000   # 矩阵维数\n",
    "density = 0.0001   # 矩阵稀疏度\n",
    "data = np.random.rand(int(n**2 * density))   # 随机矩阵元素值\n",
    "row = np.random.randint(0, n, data.size)   # 随机矩阵元素所在的行\n",
    "col = np.random.randint(0, n, data.size)   # 随机矩阵元素所在的列\n",
    "\n",
    "# 使用numpy创建COO稀疏矩阵，并记录时间\n",
    "print(\"Start creating COO sparse matrix with numpy...\")\n",
    "start = time.time()\n",
    "coo_np = coo_matrix((data, (row, col)), shape=(n,n)).tocsr()\n",
    "print(f\"Time for creating COO sparse matrix with numpy: {time.time() - start:.5f}s\")\n",
    "\n",
    "# 使用cupy创建COO稀疏矩阵，并记录时间\n",
    "print(\"Start creating COO sparse matrix with cupy...\")\n",
    "\n",
    "data_gpu = cp.asarray(data)\n",
    "row_gpu = cp.asarray(row)\n",
    "col_gpu = cp.asarray(col)\n",
    "start = time.time()\n",
    "coo_cp = cp.sparse.coo_matrix((data_gpu, (row_gpu, col_gpu)), shape=(n,n)).tocsr()\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "print(f\"Time for creating COO sparse matrix with cupy: {time.time() - start:.5f}s\")\n",
    "\n",
    "# 对COO稀疏矩阵进行乘法操作，记录时间\n",
    "print(\"Start matrix multiplication with numpy...\")\n",
    "start = time.time()\n",
    "ans_np = coo_np @ coo_np\n",
    "numpy_time = time.time() - start\n",
    "print(f\"Time for computing operations on sparse matrix with numpy: {numpy_time:.5f}s\")\n",
    "\n",
    "print(\"Start matrix multiplication with cupy...\")\n",
    "start = time.time()\n",
    "ans_cp = coo_cp @ coo_cp\n",
    "cp.cuda.Stream.null.synchronize()  # 必须等待cupy结果，因为它是异步计算的\n",
    "cupy_time = time.time() - start\n",
    "print(f\"Time for computing operations on sparse matrix with cupy: {cupy_time:.5f}s\")\n",
    "\n",
    "# 比较numpy和cupy实现的乘法操作的时间\n",
    "print(f\"Ratio of computation time(numpy/cupy): {numpy_time/cupy_time:.5f}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-02T11:18:51.957946100Z",
     "start_time": "2023-06-02T11:18:50.156193800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:2.3604259490966797\n",
      "GPU:0.021862506866455078\n"
     ]
    }
   ],
   "source": [
    "### Numpy and CPU\n",
    "s = time.time()\n",
    "x_cpu = np.ones((1000,1000,1000))\n",
    "e = time.time()\n",
    "print(f'GPU:{e - s}')\n",
    "s = time.time()\n",
    "x_gpu = cp.ones((1000,1000,1000))\n",
    "e = time.time()\n",
    "print(f'GPU:{e - s}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-02T11:18:54.353375700Z",
     "start_time": "2023-06-02T11:18:51.957946100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy创建稀疏矩阵的时间： 0.017729997634887695\n",
      "PyTorch创建稀疏矩阵的时间： 0.03204011917114258\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import random as sp_random\n",
    "\n",
    "# 创建稀疏矩阵的参数\n",
    "n = 1000  # 矩阵维度\n",
    "density = 0.01  # 非零元素的密度\n",
    "\n",
    "# 使用NumPy创建稀疏矩阵\n",
    "def create_sparse_matrix_numpy():\n",
    "    sparse_matrix = sp_random(n, n, density=density, format='csr')\n",
    "    return sparse_matrix\n",
    "\n",
    "# 使用PyTorch创建稀疏矩阵\n",
    "def create_sparse_matrix_pytorch():\n",
    "    values = torch.randn(int(n * n * density))\n",
    "    indices = torch.randint(n, (2, int(n * n * density)))\n",
    "    sparse_matrix = torch.sparse_coo_tensor(indices, values, size=(n, n))\n",
    "    return sparse_matrix\n",
    "\n",
    "# 测试NumPy创建稀疏矩阵的速度\n",
    "numpy_start_time = time.time()\n",
    "sparse_matrix_numpy = create_sparse_matrix_numpy()\n",
    "numpy_end_time = time.time()\n",
    "numpy_execution_time = numpy_end_time - numpy_start_time\n",
    "\n",
    "# 测试PyTorch创建稀疏矩阵的速度\n",
    "torch_start_time = time.time()\n",
    "sparse_matrix_pytorch = create_sparse_matrix_pytorch()\n",
    "torch_end_time = time.time()\n",
    "torch_execution_time = torch_end_time - torch_start_time\n",
    "\n",
    "# 输出结果\n",
    "print(\"NumPy创建稀疏矩阵的时间：\", numpy_execution_time)\n",
    "print(\"PyTorch创建稀疏矩阵的时间：\", torch_execution_time)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T11:18:55.591638800Z",
     "start_time": "2023-06-02T11:18:54.353375700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy创建稀疏矩阵的时间： 0.02418231964111328\n",
      "PyTorch创建稀疏矩阵的时间： 0.00040841102600097656\n",
      "CuPy创建稀疏矩阵的时间： 6.891504526138306\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import cupy as cp\n",
    "from scipy.sparse import random as sp_random\n",
    "\n",
    "# 创建稀疏矩阵的参数\n",
    "n = 1000  # 矩阵维度\n",
    "density = 0.01  # 非零元素的密度\n",
    "\n",
    "# 使用NumPy创建稀疏矩阵\n",
    "def create_sparse_matrix_numpy():\n",
    "    sparse_matrix = sp_random(n, n, density=density, format='csr')\n",
    "    return sparse_matrix\n",
    "\n",
    "# 使用PyTorch创建稀疏矩阵\n",
    "def create_sparse_matrix_pytorch():\n",
    "    values = torch.randn(int(n * n * density))\n",
    "    indices = torch.randint(n, (2, int(n * n * density)))\n",
    "    sparse_matrix = torch.sparse_coo_tensor(indices, values, size=(n, n))\n",
    "    return sparse_matrix\n",
    "\n",
    "# 使用CuPy创建稀疏矩阵\n",
    "def create_sparse_matrix_cupy():\n",
    "    values = cp.random.randn(int(n * n * density))\n",
    "    indices = cp.random.randint(n, size=(2, int(n * n * density)))\n",
    "    sparse_matrix = cp.sparse.coo_matrix((values, indices), shape=(n, n))\n",
    "    return sparse_matrix\n",
    "\n",
    "# 测试NumPy创建稀疏矩阵的速度\n",
    "numpy_start_time = time.time()\n",
    "sparse_matrix_numpy = create_sparse_matrix_numpy()\n",
    "numpy_end_time = time.time()\n",
    "numpy_execution_time = numpy_end_time - numpy_start_time\n",
    "\n",
    "# 测试PyTorch创建稀疏矩阵的速度\n",
    "torch_start_time = time.time()\n",
    "sparse_matrix_pytorch = create_sparse_matrix_pytorch()\n",
    "torch_end_time = time.time()\n",
    "torch_execution_time = torch_end_time - torch_start_time\n",
    "\n",
    "# 测试CuPy创建稀疏矩阵的速度\n",
    "cupy_start_time = time.time()\n",
    "sparse_matrix_cupy = create_sparse_matrix_cupy()\n",
    "cupy_end_time = time.time()\n",
    "cupy_execution_time = cupy_end_time - cupy_start_time\n",
    "\n",
    "# 输出结果\n",
    "print(\"NumPy创建稀疏矩阵的时间：\", numpy_execution_time)\n",
    "print(\"PyTorch创建稀疏矩阵的时间：\", torch_execution_time)\n",
    "print(\"CuPy创建稀疏矩阵的时间：\", cupy_execution_time)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T11:19:02.527360300Z",
     "start_time": "2023-06-02T11:18:55.591638800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy创建稀疏矩阵的时间： 0.02886819839477539\n",
      "CuPy创建稀疏矩阵的时间： 0.0017554759979248047\n",
      "PyTorch创建稀疏矩阵的时间： 0.000438690185546875\n",
      "PyTorch在GPU上创建稀疏矩阵的时间： 0.00054168701171875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import random as sp_random\n",
    "import time\n",
    "\n",
    "# 创建稀疏矩阵的参数\n",
    "n = 1000  # 矩阵维度\n",
    "density = 0.01  # 非零元素的密度\n",
    "\n",
    "# 使用NumPy创建稀疏矩阵\n",
    "def create_sparse_matrix_numpy():\n",
    "    sparse_matrix = sp_random(n, n, density=density, format='csr')\n",
    "    return sparse_matrix\n",
    "\n",
    "# 使用PyTorch创建稀疏矩阵\n",
    "def create_sparse_matrix_pytorch():\n",
    "    values = torch.randn(int(n * n * density))\n",
    "    indices = torch.randint(n, (2, int(n * n * density)))\n",
    "    sparse_matrix = torch.sparse_coo_tensor(indices, values, size=(n, n))\n",
    "    return sparse_matrix\n",
    "\n",
    "# 使用PyTorch在GPU上创建稀疏矩阵\n",
    "def create_sparse_matrix_pytorch_gpu():\n",
    "    values = torch.randn(int(n * n * density)).cuda()\n",
    "    indices = torch.randint(n, (2, int(n * n * density))).cuda()\n",
    "    sparse_matrix = torch.sparse_coo_tensor(indices, values, size=(n, n))\n",
    "    return sparse_matrix\n",
    "\n",
    "def create_sparse_matrix_cupy():\n",
    "    values = cp.random.randn(int(n * n * density))\n",
    "    indices = cp.random.randint(n, size=(2, int(n * n * density)))\n",
    "    sparse_matrix = cp.sparse.coo_matrix((values, indices), shape=(n, n))\n",
    "    return sparse_matrix\n",
    "\n",
    "# 测试NumPy创建稀疏矩阵的速度\n",
    "numpy_start_time = time.time()\n",
    "sparse_matrix_numpy = create_sparse_matrix_numpy()\n",
    "numpy_end_time = time.time()\n",
    "numpy_execution_time = numpy_end_time - numpy_start_time\n",
    "\n",
    "# 测试CuPy创建稀疏矩阵的速度\n",
    "cupy_start_time = time.time()\n",
    "sparse_matrix_pytorch = create_sparse_matrix_cupy()\n",
    "cupy_end_time = time.time()\n",
    "cupy_execution_time = cupy_end_time - cupy_start_time\n",
    "\n",
    "# 测试PyTorch创建稀疏矩阵的速度\n",
    "torch_start_time = time.time()\n",
    "sparse_matrix_pytorch = create_sparse_matrix_pytorch()\n",
    "torch_end_time = time.time()\n",
    "torch_execution_time = torch_end_time - torch_start_time\n",
    "\n",
    "# 测试PyTorch在GPU上创建稀疏矩阵的速度\n",
    "torch_gpu_start_time = time.time()\n",
    "sparse_matrix_pytorch_gpu = create_sparse_matrix_pytorch_gpu()\n",
    "torch_gpu_end_time = time.time()\n",
    "torch_gpu_execution_time = torch_gpu_end_time - torch_gpu_start_time\n",
    "\n",
    "# 输出结果\n",
    "print(\"NumPy创建稀疏矩阵的时间：\", numpy_execution_time)\n",
    "print(\"CuPy创建稀疏矩阵的时间：\", cupy_execution_time)\n",
    "print(\"PyTorch创建稀疏矩阵的时间：\", torch_execution_time)\n",
    "print(\"PyTorch在GPU上创建稀疏矩阵的时间：\", torch_gpu_execution_time)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T11:23:23.254555400Z",
     "start_time": "2023-06-02T11:23:23.168232500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy创建稀疏矩阵的时间： 0.025313854217529297\n",
      "PyTorch创建稀疏矩阵的时间： 0.0004525184631347656\n",
      "CuPy创建稀疏矩阵的时间： 0.0013811588287353516\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import cupy as cp\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# from jax.scipy.sparse import coo_matrix as jax_coo_matrix\n",
    "\n",
    "# 创建稀疏矩阵的参数\n",
    "n = 1000  # 矩阵维度\n",
    "density = 0.01  # 非零元素的密度\n",
    "\n",
    "# 使用NumPy创建稀疏矩阵\n",
    "def create_sparse_matrix_numpy():\n",
    "    sparse_matrix = sp_random(n, n, density=density, format='csr')\n",
    "    return sparse_matrix\n",
    "\n",
    "# 使用PyTorch创建稀疏矩阵\n",
    "def create_sparse_matrix_pytorch():\n",
    "    values = torch.randn(int(n * n * density))\n",
    "    indices = torch.randint(n, (2, int(n * n * density)))\n",
    "    sparse_matrix = torch.sparse_coo_tensor(indices, values, size=(n, n))\n",
    "    return sparse_matrix\n",
    "\n",
    "# 使用CuPy创建稀疏矩阵\n",
    "def create_sparse_matrix_cupy():\n",
    "    values = cp.random.randn(int(n * n * density))\n",
    "    indices = cp.random.randint(n, size=(2, int(n * n * density)))\n",
    "    sparse_matrix = cp.sparse.coo_matrix((values, indices), shape=(n, n))\n",
    "    return sparse_matrix\n",
    "\n",
    "# 使用JAX创建稀疏矩阵\n",
    "# def create_sparse_matrix_jax():\n",
    "#     values = jax.random.randn(int(n * n * density))\n",
    "#     indices = jax.random.randint(jax.device_get(jax.random.PRNGKey(0)), n, shape=(2, int(n * n * density)))\n",
    "#     sparse_matrix = jax_random(indices, values, shape=(n, n))\n",
    "#     return sparse_matrix\n",
    "\n",
    "# 测试NumPy创建稀疏矩阵的速度\n",
    "numpy_start_time = time.time()\n",
    "sparse_matrix_numpy = create_sparse_matrix_numpy()\n",
    "numpy_end_time = time.time()\n",
    "numpy_execution_time = numpy_end_time - numpy_start_time\n",
    "\n",
    "# 测试PyTorch创建稀疏矩阵的速度\n",
    "torch_start_time = time.time()\n",
    "sparse_matrix_pytorch = create_sparse_matrix_pytorch()\n",
    "torch_end_time = time.time()\n",
    "torch_execution_time = torch_end_time - torch_start_time\n",
    "\n",
    "# 测试CuPy创建稀疏矩阵的速度\n",
    "cupy_start_time = time.time()\n",
    "sparse_matrix_cupy = create_sparse_matrix_cupy()\n",
    "cupy_end_time = time.time()\n",
    "cupy_execution_time = cupy_end_time - cupy_start_time\n",
    "\n",
    "# # 测试JAX创建稀疏矩阵的速度\n",
    "# jax_start_time = time.time()\n",
    "# sparse_matrix_jax = create_sparse_matrix_jax()\n",
    "# jax_end_time = time.time()\n",
    "# jax_execution_time = jax_end_time - jax_start_time\n",
    "\n",
    "# 输出结果\n",
    "print(\"NumPy创建稀疏矩阵的时间：\", numpy_execution_time)\n",
    "print(\"PyTorch创建稀疏矩阵的时间：\", torch_execution_time)\n",
    "print(\"CuPy创建稀疏矩阵的时间：\", cupy_execution_time)\n",
    "# print(\"JAX创建稀疏矩阵的时间：\", jax_execution_time)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T11:19:02.642062Z",
     "start_time": "2023-06-02T11:19:02.609498900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4526, -2.2701,  0.1741],\n",
      "        [-0.6773,  0.0356,  0.4223],\n",
      "        [-0.7377, -1.8514,  1.7771]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建复数矩阵\n",
    "real_part = torch.randn(3, 3)  # 实部\n",
    "imaginary_part = torch.randn(3, 3)  # 虚部\n",
    "complex_matrix = torch.view_as_complex(torch.stack([real_part, imaginary_part], dim=-1))\n",
    "\n",
    "# 输出实部\n",
    "real_matrix = complex_matrix.real\n",
    "print(real_matrix)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T11:19:02.650260400Z",
     "start_time": "2023-06-02T11:19:02.642062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2868, -2.1745,  0.9911],\n        [ 0.2809, -0.0405, -0.7632],\n        [-1.1362, -0.1940, -1.2684]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_matrix.imag"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T11:19:02.654758100Z",
     "start_time": "2023-06-02T11:19:02.649302900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "稀疏矩阵:\n",
      "tensor(indices=tensor([[0, 1, 1, 2],\n",
      "                       [1, 0, 2, 1]]),\n",
      "       values=tensor([1., 2., 3., 4.]),\n",
      "       size=(3, 3), nnz=4, layout=torch.sparse_coo)\n",
      "转置矩阵:\n",
      "tensor(indices=tensor([[1, 0, 2, 1],\n",
      "                       [0, 1, 1, 2]]),\n",
      "       values=tensor([1., 2., 3., 4.]),\n",
      "       size=(3, 3), nnz=4, layout=torch.sparse_coo)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.sparse' has no attribute 'is_sparse'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(transpose_matrix)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# 判断矩阵是否为稀疏矩阵\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m is_sparse \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_sparse\u001B[49m(sparse_matrix)\n\u001B[1;32m     18\u001B[0m is_transpose_sparse \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msparse\u001B[38;5;241m.\u001B[39mis_sparse(transpose_matrix)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m原始矩阵是否为稀疏矩阵:\u001B[39m\u001B[38;5;124m\"\u001B[39m, is_sparse)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch.sparse' has no attribute 'is_sparse'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建稀疏矩阵\n",
    "indices = torch.tensor([[0, 1, 1, 2],\n",
    "                        [1, 0, 2, 1]], dtype=torch.long)\n",
    "values = torch.tensor([1.0, 2.0, 3.0, 4.0], dtype=torch.float)\n",
    "sparse_matrix = torch.sparse_coo_tensor(indices, values, size=(3, 3))\n",
    "\n",
    "# 输出稀疏矩阵及其转置\n",
    "print(\"稀疏矩阵:\")\n",
    "print(sparse_matrix)\n",
    "print(\"转置矩阵:\")\n",
    "transpose_matrix = sparse_matrix.t()\n",
    "print(transpose_matrix)\n",
    "\n",
    "# 判断矩阵是否为稀疏矩阵\n",
    "is_sparse = torch.sparse.is_sparse(sparse_matrix)\n",
    "is_transpose_sparse = torch.sparse.is_sparse(transpose_matrix)\n",
    "\n",
    "print(\"原始矩阵是否为稀疏矩阵:\", is_sparse)\n",
    "print(\"转置矩阵是否为稀疏矩阵:\", is_transpose_sparse)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:09:47.922211400Z",
     "start_time": "2023-06-02T12:09:47.894285800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cf 转置与 Cf 的乘积:\n",
      "tensor([[-11.+60.j,   0.+0.j,   0.+0.j,   0.+0.j,   0.+0.j],\n",
      "        [  0.+0.j,  -3.+4.j,   0.+0.j,   0.+0.j,   0.+0.j],\n",
      "        [  0.+0.j,   0.+0.j,  -7.+24.j,   0.+0.j,   0.+0.j],\n",
      "        [-13.+82.j,   0.+0.j,   0.+0.j,   0.+0.j,   0.+0.j],\n",
      "        [-15.+104.j,   0.+0.j,   0.+0.j,   0.+0.j,   0.+0.j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39355/851905299.py:8: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  Cf = torch.sparse_csr_tensor(row_indices, col_indices, values, size)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 生成 CSR 稀疏矩阵\n",
    "values = torch.tensor([1 + 2j, 3 + 4j, 5 + 6j, 7 + 8j, 9 + 10j], dtype=torch.complex64)\n",
    "row_indices = torch.tensor([0, 0, 1, 2, 3], dtype=torch.long)\n",
    "col_indices = torch.tensor([1, 2, 0, 3, 4], dtype=torch.long)\n",
    "size = (4, 5)\n",
    "Cf = torch.sparse_csr_tensor(row_indices, col_indices, values, size)\n",
    "\n",
    "# 计算 Cf 的转置矩阵\n",
    "# Cf_transpose = Cf.transpose(0, 1)\n",
    "\n",
    "# 计算 Cf 转置与 Cf 的乘积\n",
    "product = Cf.transpose(0, 1).mm(Cf)\n",
    "\n",
    "# 输出结果\n",
    "print(\"Cf 转置与 Cf 的乘积:\")\n",
    "print(product.to_dense())  # 转换为稠密矩阵并打印\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:56:47.423671Z",
     "start_time": "2023-06-02T12:56:46.143233400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::as_strided' with arguments from the 'SparseCsrCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::as_strided' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:31034 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:43986 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:26824 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:459 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at aten/src/ATen/RegisterFunctionalization_0.cpp:20475 [kernel]\nNamed: fallthrough registered at ../aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\nZeroTensor: registered at aten/src/ATen/RegisterZeroTensor.cpp:161 [kernel]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4733 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:16728 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:819 [kernel]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1077 [kernel]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mCf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: Could not run 'aten::as_strided' with arguments from the 'SparseCsrCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::as_strided' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:31034 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:43986 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:26824 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:459 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at aten/src/ATen/RegisterFunctionalization_0.cpp:20475 [kernel]\nNamed: fallthrough registered at ../aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\nZeroTensor: registered at aten/src/ATen/RegisterZeroTensor.cpp:161 [kernel]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4733 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:16728 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:819 [kernel]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1077 [kernel]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "Cf.T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:22:28.751815700Z",
     "start_time": "2023-06-02T12:22:28.717906400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "nvenv",
   "language": "python",
   "display_name": "nvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
